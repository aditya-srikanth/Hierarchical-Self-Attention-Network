{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import config\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "import pandas as pd\n",
    "\n",
    "from data_utils import *\n",
    "from model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match(outputs, labels):\n",
    "    results = []\n",
    "    for predictions,targets in zip(outputs,labels):\n",
    "        review_match = True\n",
    "        for i in range( len( predictions ) ):\n",
    "            if targets[i] == config.PAD: # special padding value, ignore this\n",
    "                continue\n",
    "\n",
    "            elif targets[i] == config.bio_dict['B']: # B tag seen\n",
    "                matched = True\n",
    "                begin = i\n",
    "                while   i < len( predictions ) and targets[i] != config.bio_dict['O'] and targets[i] != config.PAD and \\\n",
    "                        not ( i > begin and targets[i] == config.bio_dict['B'] ): # B tag not seen again\n",
    "                    \n",
    "                    if targets[i] == predictions[i]:\n",
    "                        i += 1\n",
    "                    elif targets[i] != predictions[i]:\n",
    "                        matched= False\n",
    "                        break\n",
    "                \n",
    "                review_match = review_match and matched\n",
    "        results.append( int(review_match) )\n",
    "\n",
    "    return pd.DataFrame({'predictions': results})\n",
    "\n",
    "def get_correct_indices(model,loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        print('evaluating')\n",
    "        for _,batch in enumerate( loader ):\n",
    "            batch = { k : v.to( config.device ) for k,v in batch.items()  }\n",
    "\n",
    "            targets = batch[ 'targets' ]\n",
    "            targets = pack_padded_sequence( targets, batch['original_review_length'], batch_first= True, enforce_sorted= False )\n",
    "            targets,_ = pad_packed_sequence( targets, batch_first= True, padding_value= config.PAD )\n",
    "            \n",
    "            mask = ( targets < config.PAD )\n",
    "\n",
    "            batch['targets'] = targets * mask.long()\n",
    "\n",
    "            mask = mask.unsqueeze(2).float()\n",
    "            if config.use_crf:\n",
    "                _, outputs = model( batch, mask= mask, get_predictions= True ) \n",
    "            else:\n",
    "                outputs = model( batch, mask= mask)\n",
    "                outputs = torch.argmax( outputs, dim= 1 )\n",
    "        \n",
    "        results = match(outputs, targets)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/Restaurants_Train.xml\n",
      "Number of no-aspect sentences =  1021\n",
      "Number of total reviews =  3044\n",
      "./datasets/Restaurants_Test.xml\n",
      "Number of no-aspect sentences =  194\n",
      "Number of total reviews =  800\n",
      "pre-existing mapping file\n",
      "Number of no-aspect sentences =  1021\n",
      "Number of total reviews =  3044\n",
      "vocab gen\n",
      "vocab gen complete\n",
      "review processing\n",
      "review processing complete\n",
      "Number of no-aspect sentences =  194\n",
      "Number of total reviews =  800\n",
      "vocab gen\n",
      "vocab gen complete\n",
      "review processing\n",
      "review processing complete\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab.from_files( [config.dataset_path, config.test_dataset_path], store= config.mapping_file )\n",
    "train_dataset = ReviewDataset(config.dataset_path, preprocessed= False, vocab= vocab)\n",
    "test_dataset = ReviewDataset(config.test_dataset_path, preprocessed= False, vocab= vocab)\n",
    "dataset = ConcatDataset([train_dataset,test_dataset])\n",
    "loader = DataLoader( dataset, batch_size= len( dataset ), shuffle= False, num_workers= config.num_dataset_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_dim  -1\n",
      "number of tokens:  5120  embedding dimensions:  200\n",
      "embedding matrix shape:  (5120, 200)\n",
      "retrieved embedding weights from existing file\n",
      "FusionAttentionAspectExtractionV2(\n",
      "  (embedding): Embedding(5120, 200)\n",
      "  (encoder): LSTM(200, 50, num_layers=2, dropout=0.3, bidirectional=True)\n",
      "  (w_a): Linear(in_features=100, out_features=100, bias=True)\n",
      "  (w_f): Linear(in_features=200, out_features=100, bias=False)\n",
      "  (w_r): Linear(in_features=100, out_features=3, bias=False)\n",
      "  (crf): CRF(num_tags=3)\n",
      ")\n",
      "pos_dim  -1\n",
      "number of tokens:  5120  embedding dimensions:  200\n",
      "embedding matrix shape:  (5120, 200)\n",
      "retrieved embedding weights from existing file\n",
      "AttentionAspectExtraction(\n",
      "  (embedding): Embedding(5120, 200)\n",
      "  (encoder): LSTM(200, 50, num_layers=2, dropout=0.3, bidirectional=True)\n",
      "  (w_r): Linear(in_features=100, out_features=3, bias=True)\n",
      "  (crf): CRF(num_tags=3)\n",
      ")\n",
      "pos_dim  -1\n",
      "number of tokens:  5120  embedding dimensions:  200\n",
      "embedding matrix shape:  (5120, 200)\n",
      "retrieved embedding weights from existing file\n",
      "AttentionAspectExtraction(\n",
      "  (embedding): Embedding(5120, 200)\n",
      "  (encoder): LSTM(200, 50, num_layers=2, dropout=0.3, bidirectional=True)\n",
      "  (w_r): Linear(in_features=100, out_features=3, bias=True)\n",
      "  (crf): CRF(num_tags=3)\n",
      ")\n",
      "number of tokens:  5120  embedding dimensions:  200\n",
      "embedding matrix shape:  (5120, 200)\n",
      "retrieved embedding weights from existing file\n",
      "BaseLineLSTM(\n",
      "  (embedding): Embedding(5120, 200)\n",
      "  (encoder): LSTM(200, 50, num_layers=2, dropout=0.3, bidirectional=True)\n",
      "  (w_r): Linear(in_features=100, out_features=3, bias=True)\n",
      "  (crf): CRF(num_tags=3)\n",
      "  (drouput_layer): Dropout(p=0.3, inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "f_model = FusionAttentionAspectExtractionV2( vocab, embedding_path= config.word_embedding_path, use_crf= config.use_crf )\n",
    "f_model.load_state_dict(torch.load('./model_weights/'+config.dataset+'_fusionv2_'+config.embedding+'.pt')) \n",
    "f_model = f_model.to(config.device)\n",
    "print(f_model)\n",
    "\n",
    "a_model = AttentionAspectExtraction( vocab, embedding_path= config.word_embedding_path, use_crf= config.use_crf )\n",
    "a_model.load_state_dict(torch.load('./model_weights/'+config.dataset+'_attention_lstm_'+config.embedding+'.pt')) \n",
    "a_model = a_model.to(config.device)\n",
    "print(a_model)\n",
    "\n",
    "g_model = GlobalAttentionAspectExtraction( vocab, embedding_path= config.word_embedding_path, use_crf= config.use_crf )\n",
    "g_model.load_state_dict(torch.load('./model_weights/'+config.dataset+'_global_attention_lstm_'+config.embedding+'.pt')) \n",
    "g_model = a_model.to(config.device)\n",
    "print(a_model)\n",
    "\n",
    "b_model = BaseLineLSTM( vocab, embedding_path= config.word_embedding_path, use_crf= config.use_crf )\n",
    "b_model.load_state_dict(torch.load('./model_weights/'+config.dataset+'_lstm_'+config.embedding+'.pt')) \n",
    "b_model = b_model.to(config.device)\n",
    "print(b_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluating\n"
     ]
    }
   ],
   "source": [
    "# f_results = get_correct_indices(f_model, loader)\n",
    "# a_results = get_correct_indices(a_model, loader)\n",
    "# b_results = get_correct_indices(b_model, loader)\n",
    "g_results = get_correct_indices(g_model, loader)\n",
    "\n",
    "# a_correct = a_results & ~b_results \n",
    "# f_correct = f_results & ~a_results & ~b_results\n",
    "\n",
    "# f_results.to_csv('./results/'+ config.dataset +'_fusionv2_predictions.csv', index= False)\n",
    "# a_results.to_csv('./results/'+ config.dataset +'_attention_lstm_predictions.csv', index= False)\n",
    "# b_results.to_csv('./results/'+ config.dataset +'_bilstm_predictions.csv', index= False)\n",
    "g_results.to_csv('./results/'+ config.dataset +'_global_attention_lstm_predictions.csv', index= False)\n",
    "\n",
    "# f_correct.to_csv('./results/'+ config.dataset +'_fusionv2_correct_predictions.csv', index= False)\n",
    "# a_correct.to_csv('./results/'+ config.dataset +'_attention_lstm_correct_predictions.csv', index= False)\n",
    "\n",
    "# print(f_results)\n",
    "# print(a_results)\n",
    "# print(b_results)\n",
    "# print(a_correct)\n",
    "# print(f_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## load pre generated results ############\n",
    "f_results = pd.read_csv('./results/'+ config.dataset +'_fusionv2_predictions.csv')\n",
    "a_results = pd.read_csv('./results/'+ config.dataset +'_attention_lstm_predictions.csv')\n",
    "b_results = pd.read_csv('./results/'+ config.dataset +'_bilstm_predictions.csv')\n",
    "g_results = pd.read_csv('./results/'+ config.dataset +'_global_attention_lstm_predictions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3844\n",
      "generating scores\n",
      "torch.Size([364, 1, 79])\n",
      "evaluating\n",
      "torch.Size([218, 79, 79])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f_fail = np.squeeze(1 - f_results.values)\n",
    "g_fail = np.squeeze(1 - g_results.values)\n",
    "\n",
    "f_fail = np.squeeze(np.argwhere(f_fail == 1)).tolist()\n",
    "g_fail = np.squeeze(np.argwhere(g_fail == 1)).tolist()\n",
    "\n",
    "# print(f_fail)\n",
    "# print(g_fail)\n",
    "\n",
    "dataset = train_dataset.get_review_list() + test_dataset.get_review_list()\n",
    "print(len(dataset))\n",
    "f_reviews = [ dataset[i] for i in list(f_fail) ]\n",
    "g_reviews = [ dataset[i] for i in list(g_fail) ]\n",
    "\n",
    "\n",
    "\n",
    "with open('./results/'+ config.dataset +'_fusion_fail_sentences.txt','w') as f:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        f_model.eval()\n",
    "        print('generating scores')\n",
    "        for _,batch in enumerate( loader ):\n",
    "            batch = { k : v.to( config.device ) for k,v in batch.items()  }\n",
    "\n",
    "            targets = batch[ 'targets' ]\n",
    "            targets = pack_padded_sequence( targets, batch['original_review_length'], batch_first= True, enforce_sorted= False )\n",
    "            targets,_ = pad_packed_sequence( targets, batch_first= True, padding_value= config.PAD )\n",
    "            \n",
    "            mask = ( targets < config.PAD )\n",
    "\n",
    "            batch['targets'] = targets * mask.long()\n",
    "\n",
    "            mask = mask.unsqueeze(2).float()\n",
    "            if config.use_crf:\n",
    "                _, outputs, global_context, beta = f_model( batch, mask= mask, get_predictions= True, yield_attention_weights= True ) \n",
    "            else:\n",
    "                outputs, global_context, beta = f_model( batch, mask= mask, yield_attention_weights= True)\n",
    "                outputs = torch.argmax( outputs, dim= 1 )\n",
    "        \n",
    "        betas = torch.stack([ beta[ i , :, : ] for i in f_fail ])\n",
    "        global_scores = torch.stack([ global_context[ i ] for i in f_fail ])\n",
    "        print(global_scores.shape)\n",
    "#         for i,g in enumerate(global_scores):\n",
    "#             print(i,g)\n",
    "#         input()\n",
    "        torch.save(betas,'./model_weights/'+config.dataset+'_fusion_fail_beta_scores.pt')\n",
    "        torch.save(global_scores,'./model_weights/'+config.dataset+'_fusion_fail_global_context_scores.pt')\n",
    "\n",
    "        for review, global_score, beta in zip(f_reviews, global_scores, betas):\n",
    "            if len(review.aspect_terms) > 1 and max([len(aspect) for aspect in review.aspect_terms ]) > 1:\n",
    "                f.write(review.text +' ####### '+ str(review.aspect_terms) + '\\n')\n",
    "\n",
    "with open('./results/'+ config.dataset +'_global_attention_fail_sentences.txt','w') as f:\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        g_model.eval()\n",
    "        print('evaluating')\n",
    "        for _,batch in enumerate( loader ):\n",
    "            batch = { k : v.to( config.device ) for k,v in batch.items()  }\n",
    "\n",
    "            targets = batch[ 'targets' ]\n",
    "            targets = pack_padded_sequence( targets, batch['original_review_length'], batch_first= True, enforce_sorted= False )\n",
    "            targets,_ = pad_packed_sequence( targets, batch_first= True, padding_value= config.PAD )\n",
    "            \n",
    "            mask = ( targets < config.PAD )\n",
    "\n",
    "            batch['targets'] = targets * mask.long()\n",
    "\n",
    "            mask = mask.unsqueeze(2).float()\n",
    "            if config.use_crf:\n",
    "                _, outputs, beta = g_model( batch, mask= mask, get_predictions= True, yield_attention_weights= True ) \n",
    "            else:\n",
    "                outputs, beta = g_model( batch, mask= mask, yield_attention_weights= True)\n",
    "                outputs = torch.argmax( outputs, dim= 1 )\n",
    "        \n",
    "        betas = torch.stack([ beta[ i , :, : ] for i in g_fail ])\n",
    "        torch.save(betas,'./model_weights/'+config.dataset+'_global_attention_lstm_fail_beta_scores.pt')\n",
    "        print(betas.shape)\n",
    "\n",
    "\n",
    "    for review, beta in zip(g_reviews, betas):\n",
    "        if len(review.aspect_terms) > 1 and max([len(aspect) for aspect in review.aspect_terms ]) > 1:\n",
    "            f.write(review.text + '########' + str(review.aspect_terms) + '\\n')   \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
